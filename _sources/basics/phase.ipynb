{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase\n",
    "=====\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FTQbiNvZqaY\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n",
    "</p>\n",
    "\n",
    "```{dropdown} Video not working?\n",
    "Here is a <a href=\"\">OneDrive link</a> to the full video.\n",
    "<a href=\"\"></a>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "other": {
     "more": true
    },
    "tags": [
     "hide-output",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Imports for this notebook\n",
    "\n",
    "# from ipywidgets import interact\n",
    "import numpy as np\n",
    "\n",
    "# from bokeh.io import push_notebook, show, output_notebook\n",
    "# from bokeh.plotting import figure\n",
    "# output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While many source separation papers mainly focus on their approaches for creating\n",
    "better mask estimates, which only apply to the magnitude components of a\n",
    "{term}`TF Representation`, the other crucial aspect of sound is its phase.\n",
    "\n",
    "In this section, we will discuss the important problem of how to turn a magnitude\n",
    "spectrogram of an estimated source back into a waveform so that we may listen to\n",
    "the source estimation.\n",
    "\n",
    "\n",
    "## Phase - A Quick Primer\n",
    "\n",
    "[[PHASE IMAGE]]\n",
    "\n",
    "An audio signal, $y(t)$, composed of exactly one sine wave,\n",
    "\n",
    "$$\n",
    "y(t) = A \\sin (2 \\pi f t + \\phi)\n",
    "$$\n",
    "\n",
    "can be completely described by the parameters $t, A, f$ and $\\phi$, where\n",
    "$t$ represents time in seconds, $A$ is the wave's amplitude (unit-less), $f$ is\n",
    "its frequency in Hz, and $\\phi$ is its phase offset in radians (_i.e.,_ where\n",
    "in the cycle the wave is at $t=0$). If $\\phi \\ne 0$, then the sine wave appears\n",
    "shifted in time by $\\frac{\\phi}{2 \\pi f}$, where negative values \"delay\" the\n",
    "signal and positive values \"advance\" it. Recall that a sine wave is the same\n",
    "value every $2 \\pi f$ seconds,\n",
    "_i.e._\n",
    "\n",
    "$$\n",
    "\\sin (0) = \\sin(2 \\pi f) = \\sin(2k \\pi f) ~ \\forall ~ k \\in \\mathbb{Z}.\n",
    "$$\n",
    "\n",
    "This is inherent the periodicity of the sine wave, and the point where the phase\n",
    "\"wraps around\" or essentially restarts at 0 every $2 \\pi f$ seconds.\n",
    "\n",
    "Let's scale this up. Our old pal Fourier told us that\n",
    "[any sound can be represented as an infinite summation of sine waves](https://en.wikipedia.org/wiki/Fourier_transform)\n",
    "each with their own amplitudes, frequencies, and phase offsets. This means that any sound\n",
    "we hear can be represented as many, many tuples of $(t, A, f, \\phi)$.\n",
    "\n",
    "Let's think back\n",
    "to the section about time-frequency representations: each bin is index by time\n",
    "along the x-axis and frequency along the y-axis.\n",
    "We'll be a little hand-wavy here, but we can think of a {term}`TF bin` as a \"snapshot\"\n",
    "of the sound at that particular time and at that particular frequency component.\n",
    "In a magnitude spectrogram, power spectrogram, log spectrogram, etc, each value\n",
    "represents the sound's energy for that frequency at that time. So, if you're keeping\n",
    "track at home, a spectrogram has entries for $t, A$ and $f$, but _no representation\n",
    "for the phase $\\phi$._\n",
    "\n",
    "Phase is crucial to be able to describe and audio signal. Why don't most source separation\n",
    "approaches model phase information?\n",
    "\n",
    "## Why We Don't Model Phase\n",
    "\n",
    "[[REAL PHASE & GAUSSIAN NOISE]]\n",
    "\n",
    "Let's do a little experiment. Above are two images. One of the two images shows\n",
    "the phase component of an audio signal, the other shows gaussian noise. Can you\n",
    "guess which is which?\n",
    "\n",
    "Therein lies the problem: there is a complicated interplay between how the\n",
    "{term}`DFT` captures the signal at each time step, how the frequency is captured\n",
    "and how the phase is captured. Let's build some intuition for why this is.\n",
    "For the same time step, the lower frequency components of the signal change less\n",
    "quickly than the higher frequency components. This means that for any two adjacent\n",
    "time steps, the time difference is the same but the amount of change of any frequency\n",
    "might not be the same. The phase wraparound happens much quicker at the higher frequencies\n",
    "than at the lower frequencies.\n",
    "\n",
    "For instance, let's say we have a sound wave that is composed\n",
    "of two sine waves that have frequency $440$ Hz and $523.25$ Hz, which are A440 and\n",
    "the C note above A440 respectively. Both start at the origin at time $t = 0$.\n",
    "Let's look at the value of each of these sine waves at different time intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "other": {
     "more": true
    }
   },
   "outputs": [],
   "source": [
    "time = np.linspace(0.0, 0.05, 2000)\n",
    "f1 = 440.0   # A440\n",
    "f2 = 523.25  # C above A440\n",
    "sin1 = np.sin(2 * np.pi * f1 * time)\n",
    "\n",
    "offset = 3\n",
    "sin2 = np.sin(2 * np.pi * f2 * time) + offset\n",
    "\n",
    "# for i, t in enumerate(time):\n",
    "#     print(f'sin1({t:.1f}) = {sin1[i]:+.3f},\\tsin2({t:.1f}) = {sin2[i]:+.3f}')\n",
    "\n",
    "# p = figure(title=\"Phase Example\", plot_height=400, plot_width=700, y_range=(-1.5, 4.5),\n",
    "#            background_fill_color='#efefef')\n",
    "# r1 = p.line(time, sin1, color=\"#8888cc\", line_width=1.5, alpha=0.8)\n",
    "# r2 = p.line(time, sin2, color=\"#cc88cc\", line_width=1.5, alpha=0.8)\n",
    "#\n",
    "# def update(f2_=523.25, phi_=0.0):\n",
    "#     sin2_ = np.sin(2 * np.pi * f2_ * time + phi_) + offset\n",
    "#     r2.data_source.data['y'] = sin2_\n",
    "#     push_notebook()\n",
    "#\n",
    "# show(p, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "other": {
     "more": true
    }
   },
   "outputs": [],
   "source": [
    "# interact(update, f2_=(440.0, 880.0), phi_=(0, 4 * np.pi, 0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we take snapshots of each sine wave, it's difficult to find a pattern between\n",
    "the two (other than, y'know, the sine wave we drew them from).\n",
    "Another difficulty is that humans do not always perceive phase offsets,, _i.e._,\n",
    "a sine wave with $\\phi = 0$ sounds the same as a sine wave with $\\phi` \\ne 0$\n",
    "\n",
    "This is all to say that getting phase right is _hard_. That being said, there are ways\n",
    "to estimate phase, but few if any source separation approaches\n",
    "(or sound generation models) attempt to explicitly model phase to the same extent\n",
    "that magnitude information is modeled. We will discuss some of these phase estimation\n",
    "techniques below.\n",
    "\n",
    "## How to Deal with Phase\n",
    "\n",
    "In this section, we will touch on some approaches to dealing with phase information\n",
    "in source separation.\n",
    "\n",
    "### The Easy Way\n",
    "\n",
    "For a mask-based source separation approach, a easy and very common way to deal with phase\n",
    "is to just **copy the phase from the mixture!**\n",
    "The mixture phase is sometimes referred to as the _noisy phase_.\n",
    "This strategy isn't perfect, but researchers have discovered that it works surprisingly well, and\n",
    "when things go wrong, it's usually not the fault of the phase.\n",
    "\n",
    "So now, with this in place, we finally have our first strategy to convert our\n",
    "source estimate back to a waveform. Assume we have a mixture STFT,\n",
    "$Y \\in \\mathbb{C}^{T \\times F}$, and estimated mask\n",
    "$\\hat{M}_i \\in [0.0, 1.0]^{T \\times F}$ for Source $i$.\n",
    "Recall that we can apply the mask to a magnitude spectrogram of $Y$ like so:\n",
    "\n",
    "$$\n",
    "\\hat{X}_i = \\hat{M}_i \\odot |Y|\n",
    "$$\n",
    "\n",
    "where $\\hat{X}_i \\in \\mathbb{R}^{T \\times F}$ represents a magnitude spectrogram of\n",
    "our source estimate. Note that this equation looks similar if we want to apply\n",
    "a mask to a power spectrogram ($|Y|^2$), log spectrogram ($\\log |Y|$), etc.\n",
    "\n",
    "Now we can just copy the phase from the mixture over to the magnitude spectrogram\n",
    "of our source estimate, $\\hat{X_i}$:\n",
    "\n",
    "$$\n",
    "\\tilde{X}_i = \\hat{X}_i \\odot e^{j \\cdot \\angle Y}\n",
    "$$\n",
    "\n",
    "where we use $j = \\sqrt{-1}$, \"$\\angle$\" to represent the angle of the complex-valued\n",
    "{term}`STFT` of $Y$, and $\\tilde{X}_i \\in \\mathbb{C}^{T \\times F}$ to indicate\n",
    "that the estimate for Source $i$ is now complex-valued similar to an {term}`STFT`.\n",
    "\n",
    "Putting it all together it looks like:\n",
    "\n",
    "$$\n",
    "\\tilde{X_i} = (\\hat{M}_i \\odot |Y|) \\odot e^{j \\cdot \\angle Y}.\n",
    "$$\n",
    "\n",
    "This math looks pretty complicated, but this is really just a few lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "other": {
     "more": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def apply_mask_with_noisy_phase(mix_stft, mask):\n",
    "    mix_magnitude, mix_phase = np.abs(mix_stft), np.angle(mix_stft)\n",
    "    src_magnitude = mix_mag * mask\n",
    "    src_stft = src_magnitude * np.exp(1j * mix_phase)\n",
    "    return src_stft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Hard Way, Part 1: Phase Estimation\n",
    "\n",
    "It is possible to _estimate_ the phase once the estimated mask is applied to the\n",
    "mixture spectrogram. One popular way is the Griffin-Lim algorithm, which can\n",
    "iteratively reconstruct the phase component of a spectrogram by...\n",
    "\n",
    "MISI\n",
    "\n",
    "It's worth noting that the STFT & iSTFT computations, and these phase estimation\n",
    "algorithms are all differentiable and researchers have made models that\n",
    "\n",
    "\n",
    "### The Hard Way, Part 2:  Waveform Estimation\n",
    "\n",
    "Finally, a recent way that researchers have been tackling the phase problem is\n",
    "by side-stepping any explicit representations of it at all. Recently, many\n",
    "deep learning-based models have been proposed that are \"end-to-end\", meaning that\n",
    "the model's input and output are all waveforms. In this case, the model decides\n",
    "how to represent phase.\n",
    "\n",
    "\n",
    "\n",
    "[^fn1]: The amplitude, loudness, and energy of a sound are all calculated differently\n",
    " but still related. Here we will use \"amplitude\" as a stand-in for whichever one you\n",
    " choose."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "source_map": [
   11,
   26,
   41,
   118,
   149,
   155,
   215,
   228
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 4
}